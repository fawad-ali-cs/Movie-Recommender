{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "from functions import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('data/user_rating_pt.csv')\n",
    "rating_df.columns = rating_df.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_treshold = 3.5\n",
    "\n",
    "rating_df[rating_df < rating_treshold] = 0\n",
    "rating_df[rating_df >= rating_treshold] = 1\n",
    "rating_df.columns = range(len(rating_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = np.array(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known = []\n",
    "\n",
    "for u in range(rating_matrix.shape[0]):\n",
    "    for i in range(rating_matrix.shape[1]):\n",
    "        if rating_matrix[u,i] > 0:\n",
    "            known.append((u, i))\n",
    "\n",
    "training, testing = train_test(known, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((rating_matrix.shape[0], rating_matrix.shape[1]))\n",
    "test_matrix = np.zeros((rating_matrix.shape[0], rating_matrix.shape[1]))\n",
    "\n",
    "for u, i in training:\n",
    "    train_matrix[u][i] = 1\n",
    "\n",
    "for u, i in testing:\n",
    "    test_matrix[u][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_matrix, user_rec):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for u in range(user_rec.shape[0]):\n",
    "        for i in user_rec[u]:\n",
    "            if test_matrix[u][i] == 1:\n",
    "                true_positive+=1\n",
    "            else:\n",
    "                false_positive+=1\n",
    "                \n",
    "    for u in range(test_matrix.shape[0]):\n",
    "        for i in range(test_matrix.shape[1]):\n",
    "            if test_matrix[u][i] == 1 and i not in user_rec[u]:\n",
    "                false_negative+=1\n",
    "    \n",
    "    precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_negative)\n",
    "    F1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "    print(\"Precision :\", precision)\n",
    "    print(\"Recall :\", recall)\n",
    "    print(\"F1 Score :\", F1_score)\n",
    "    \n",
    "    return precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(pred, k=5):\n",
    "    rec_list = []\n",
    "    \n",
    "    for u in range(pred.shape[0]):\n",
    "        rec = np.argpartition(pred[u],-k)[-k:]\n",
    "        rec_list.append(rec)\n",
    "    \n",
    "    return np.array(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LREC(dataset, reg=1.0, user_list=None):\n",
    "    \n",
    "    if user_list == None:\n",
    "        user_list = range(dataset.shape[0])\n",
    "        \n",
    "    X = dataset.T\n",
    "    Y = X*2 - 1\n",
    "   \n",
    "    W = []\n",
    "\n",
    "    for index in user_list:\n",
    "        if 1 in Y.T[index] and -1 in Y.T[index]:\n",
    "            rdg = Ridge(alpha=reg).fit(X, Y.T[index])\n",
    "            \n",
    "            W.append(rdg.coef_)\n",
    "        else:\n",
    "            W.append(np.zeros(dataset.shape[0]))\n",
    "    \n",
    "        \n",
    "    if user_list == range(dataset.shape[0]):     \n",
    "        W = np.array(W)\n",
    "        pred = np.dot(W.T, dataset[user_list])\n",
    "\n",
    "    else:\n",
    "        W = np.array(W)\n",
    "        pred = np.dot(W, dataset)\n",
    "        \n",
    "        \n",
    "    train_replace = pred.min() - 1\n",
    "    for index, u in enumerate(user_list):\n",
    "        user_ratings = dataset[u]\n",
    "        liked_movies = np.where(user_ratings == 1)[0]\n",
    "            \n",
    "        for i in liked_movies:\n",
    "            pred[index][i] = train_replace\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.2500546448087432\n",
      "Recall : 0.12357547934107481\n",
      "F1 Score : 0.1654075546719682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2500546448087432, 0.12357547934107481, 0.1654075546719682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ = LREC(train_matrix, reg=250)\n",
    "user_rec = get_recommendations(pred_, k=15)\n",
    "\n",
    "get_metrics(test_matrix, user_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2257,   46,  659, ...,  938,  921,  913],\n",
       "       [7022, 8287, 3633, ..., 5901, 6134, 4791],\n",
       "       [ 989,  913,  835, ..., 1390,  914,  901],\n",
       "       ...,\n",
       "       [5363,  314, 4900, ..., 3609, 2224,  254],\n",
       "       [ 257,  472,  507, ...,  277,  322,  508],\n",
       "       [ 906,  224, 3868, ..., 7355, 3633, 3609]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13360095024108887"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "pred_1 = LREC(train_matrix, reg=250, user_list=[45])\n",
    "user_rec1 = get_recommendations(pred_1, k=15)\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472, 436, 297,  43, 510, 217, 287, 134, 507, 418, 307, 314, 506,\n",
       "        123, 508]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([472, 436, 297,  43, 510, 217, 287, 134, 507, 418, 307, 314, 506,\n",
       "       123, 508])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rec[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
